{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file implements the graph evolutions by generating synthetic review and affliation data, connecting to the neo4j database and finally executing cypher commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "from neo4j import GraphDatabase\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER NEO4J CREDENTIALS HERE\n",
    "uri = \"bolt://localhost:7687\"  \n",
    "username = \"neo4j\"  \n",
    "password = \"12345678\"  \n",
    "import_folder = \"/opt/homebrew/Cellar/neo4j/5.19.0/libexec/import\" # CHANGE THIS TO YOUR IMPORT FOLDER OF DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories in use:\n",
      "home:         /opt/homebrew/Cellar/neo4j/5.19.0/libexec\n",
      "config:       /opt/homebrew/Cellar/neo4j/5.19.0/libexec/conf\n",
      "logs:         /opt/homebrew/var/log/neo4j\n",
      "plugins:      /opt/homebrew/Cellar/neo4j/5.19.0/libexec/plugins\n",
      "import:       /opt/homebrew/Cellar/neo4j/5.19.0/libexec/import\n",
      "data:         /opt/homebrew/var/neo4j/data\n",
      "certificates: /opt/homebrew/Cellar/neo4j/5.19.0/libexec/certificates\n",
      "licenses:     /opt/homebrew/Cellar/neo4j/5.19.0/libexec/licenses\n",
      "run:          /opt/homebrew/Cellar/neo4j/5.19.0/libexec/run\n",
      "Starting Neo4j.\n",
      "Started neo4j (pid:14139). It is available at http://localhost:7474\n",
      "There may be a short delay until the server is ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start neo4j\n",
    "try:\n",
    "    command = \"neo4j start\"\n",
    "    result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Failed to start neo4j - it may already be running\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating fake reviews: 100%|██████████| 15000/15000 [00:00<00:00, 17976.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files for reviews generated.\n"
     ]
    }
   ],
   "source": [
    "# Import reviewed_for relationship file\n",
    "reviewed_paper = pd.read_csv('data/r_reviewed_paper.csv')\n",
    "reviewed_paper.head()\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Lists to store the new data\n",
    "reviews = []\n",
    "reviewed_by = []\n",
    "review_for = []\n",
    "\n",
    "# Loop through each row in the reviewed_paper dataframe\n",
    "for index, row in tqdm(reviewed_paper.iterrows(), total=reviewed_paper.shape[0], desc=\"Creating fake reviews\"):\n",
    "    review_id = str(uuid.uuid4())\n",
    "    content = fake.text()\n",
    "    suggested_decision = random.choice(['Accept', 'Reject', 'Revise'])\n",
    "    reviewer_id = row[':START_ID']\n",
    "    paper_id = row[':END_ID']\n",
    "    \n",
    "    # Create Review node\n",
    "    reviews.append({\n",
    "        'Id:ID': review_id,\n",
    "        'content': content,\n",
    "        'suggested_decision': suggested_decision\n",
    "    })\n",
    "\n",
    "    # Create REVIEWED relationship\n",
    "    reviewed_by.append({\n",
    "        ':START_ID': review_id,\n",
    "        ':END_ID': reviewer_id\n",
    "    })\n",
    "\n",
    "    # Create REVIEWED_FOR relationship\n",
    "    review_for.append({\n",
    "        ':START_ID': review_id,\n",
    "        ':END_ID': paper_id\n",
    "    })\n",
    "    \n",
    "\n",
    "# Save to csv\n",
    "reviews_df = pd.DataFrame(reviews)\n",
    "reviewed_by_df = pd.DataFrame(reviewed_by)\n",
    "reviewed_for_df = pd.DataFrame(review_for)\n",
    "\n",
    "review_file = f\"{import_folder}/reviews.csv\"\n",
    "reviewed_by_file = f\"{import_folder}/reviewed_by.csv\"\n",
    "reviewed_for_file = f\"{import_folder}/reviewed_for.csv\"\n",
    "\n",
    "reviews_df.to_csv(review_file, index=False)\n",
    "reviewed_by_df.to_csv(reviewed_by_file, index=False)\n",
    "reviewed_for_df.to_csv(reviewed_for_file, index=False)\n",
    "\n",
    "print(\"CSV files for reviews generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate affliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COMPANIES = 50\n",
    "NUM_UNIVERSITIES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating affiliations: 100%|██████████| 100/100 [00:00<00:00, 41319.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizations and affiliations CSV files generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "authors = pd.read_csv('data/authors.csv')\n",
    "\n",
    "# Generate nodes of universities and companies\n",
    "organizations = [\n",
    "    {'Id:ID': str(uuid.uuid4()),\n",
    "      'name': fake.company(),\n",
    "        'type': 'Company'} for _ in range(NUM_COMPANIES)\n",
    "] + [\n",
    "    {'Id:ID': str(uuid.uuid4()),\n",
    "      'name': fake.company() + \"University\",\n",
    "        'type': 'University'} for _ in range(NUM_UNIVERSITIES)\n",
    "]\n",
    "\n",
    "# Assign each author to a random organization / university\n",
    "affiliations = []\n",
    "for _, author in tqdm(authors.iterrows(), total=authors.shape[0], desc=\"Creating affiliations\"):\n",
    "    org = random.choice(organizations)\n",
    "    affiliations.append({\n",
    "        ':START_ID': author['Id:ID'],\n",
    "        ':END_ID': org['Id:ID']\n",
    "    })\n",
    "\n",
    "# Save organizations to CSV\n",
    "organizations_df = pd.DataFrame(organizations)\n",
    "organizations_df.to_csv(f\"{import_folder}/organizations.csv\", index=False)\n",
    "\n",
    "# Save affiliations to CSV\n",
    "affiliations_df = pd.DataFrame(affiliations)\n",
    "affiliations_df.to_csv(f'{import_folder}/r_affiliated_with.csv', index=False)\n",
    "\n",
    "print(\"Organizations and affiliations CSV files generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to the Neo4j database\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Create query execution function\n",
    "def execute_query(query):\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            session.run(query)\n",
    "        print(\"Successfull\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull\n"
     ]
    }
   ],
   "source": [
    "# Define the Cypher query to create Review nodes \n",
    "cypher_query_review_node = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM 'file:///reviews.csv' AS row\n",
    "CREATE (:REVIEW {Id: row.`Id:ID`, name: row.name, type: row.type, suggested_decision: row.suggested_decision})\n",
    "\"\"\"\n",
    "\n",
    "execute_query(cypher_query_review_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Cypher query to create REVIEWED_BY relationship\n",
    "cypher_query_reviewed_by = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM 'file:///reviewed_by.csv' AS row\n",
    "MATCH (a:REVIEW {Id: row.`:START_ID`}), (b:AUTHOR {Id: row.`:END_ID`})\n",
    "CREATE (a)-[:REVIEW_AUTHOR]->(b)\n",
    "\"\"\"\n",
    "\n",
    "execute_query(cypher_query_reviewed_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull\n"
     ]
    }
   ],
   "source": [
    "# Define the Cypher query to create REVIEWED_FOR relationship\n",
    "cypher_query_reviewed_for = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM 'file:///reviewed_for.csv' AS row\n",
    "MATCH (a:REVIEW {Id: row.`:START_ID`}), (b:PAPER {Id: row.`:END_ID`})\n",
    "CREATE (a)-[:REVIEWED_FOR]->(b)\n",
    "\"\"\"\n",
    "\n",
    "execute_query(cypher_query_reviewed_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull\n"
     ]
    }
   ],
   "source": [
    "# Delete publised_in relationship if majority of reviews didnt say accept\n",
    "delete_published_in_query = \"\"\"\n",
    "MATCH (r:REVIEW)-[:REVIEWED_FOR]->(p:PAPER)\n",
    "WITH p, \n",
    "     SUM(CASE WHEN r.suggested_decision = 'Accept' THEN 1 ELSE 0 END) AS acceptCount,\n",
    "     SUM(CASE WHEN r.suggested_decision IN ['Reject', 'Revise'] THEN 1 ELSE 0 END) AS rejectOrReviseCount,\n",
    "     COUNT(r) AS totalReviews\n",
    "WHERE rejectOrReviseCount > acceptCount\n",
    "MATCH (p)-[rel:PUBLISHED_IN]->(j:JOURNAL)\n",
    "DELETE rel\n",
    "RETURN p.title AS PaperTitle, j.name AS Journal\n",
    "\"\"\"\n",
    "\n",
    "execute_query(delete_published_in_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull\n"
     ]
    }
   ],
   "source": [
    "# Define the Cypher query to create organization nodes\n",
    "cypher_query_organization = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM 'file:///organizations.csv' AS row\n",
    "CREATE (:ORGANIZATION {Id: row.`Id:ID`, name: row.name, type: row.type})\n",
    "\"\"\"\n",
    "\n",
    "execute_query(cypher_query_organization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull\n"
     ]
    }
   ],
   "source": [
    "# Define the Cypher query to create affiliation relationships\n",
    "cypher_query_affiliation = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM 'file:///r_affiliated_with.csv' AS row\n",
    "MATCH (a:AUTHOR {Id: row.`:START_ID`}), (o:ORGANIZATION {Id: row.`:END_ID`})\n",
    "CREATE (a)-[:AFFILIATED_WITH]->(o);\n",
    "\"\"\"\n",
    "execute_query(cypher_query_affiliation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
