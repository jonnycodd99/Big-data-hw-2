{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file generates fake data for the initial graph using Faker. This is then stored in csv file ready to be uploaded to neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nodes:\n",
    "    * Author: { Id:ID, name, email }\n",
    "    * Keyword: { Id:ID, keyword }\n",
    "    * Conference_Workshop: { Id:ID, name, type, city, edition:INT, date, year:INT, month:INT, day:INT }\n",
    "    * Journal: { Id:ID, name, volume:INT, year:INT }\n",
    "    * Paper: { Id:ID, title, abstract, date, year:INT, month:INT, day:INT, pages:INT, doi, type }\n",
    "* Relationships:\n",
    "    * WRITTEN_BY: (:Author)-[:WRITTEN_BY]->(:Paper)\n",
    "    * CORRESPONDING_AUTHOR: (:Author)-[:CORRESPONDING_AUTHOR]->(:Paper)\n",
    "    * PUBLISHED_IN: (:Paper)-[:PUBLISHED_IN]->(:Journal|:Conference|:Workshop)\n",
    "    * CITES: (:Paper)-[:CITES]->(:Paper)\n",
    "    * HAS_KEYWORD: (:Paper)-[:HAS_KEYWORD]->(:Keyword)\n",
    "    * REVIEWED_BY: (:Review)-[:REVIEWED_BY]->(:Author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "# Define the number of each entity to generate\n",
    "NUM_AUTHORS = 100\n",
    "NUM_PAPERS = 5000\n",
    "NUM_CONFERENCES = 5\n",
    "NUM_JOURNALS = 5\n",
    "NUM_KEYWORDS = 1000\n",
    "\n",
    "START_YEAR = 2010\n",
    "END_YEAR = 2023\n",
    "START_DATE = datetime(START_YEAR, 1, 1)\n",
    "END_DATE = datetime(END_YEAR, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "# Define the number of each entity to generate\n",
    "NUM_AUTHORS = 100\n",
    "NUM_PAPERS = 5000\n",
    "NUM_CONFERENCES = 5\n",
    "NUM_JOURNALS = 2\n",
    "NUM_KEYWORDS = 500\n",
    "\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2023\n",
    "START_DATE = datetime(START_YEAR, 1, 1)\n",
    "END_DATE = datetime(END_YEAR, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords generated\n",
      "conferences and workshops generated\n",
      "journals generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Papers: 100%|██████████| 5000/5000 [00:00<00:00, 12529.95paper/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers generated\n",
      "citations generated\n",
      "paper keywords generated\n"
     ]
    }
   ],
   "source": [
    "# Generate Authors\n",
    "authors = []\n",
    "for _ in range(NUM_AUTHORS):\n",
    "    authors.append({\n",
    "        'Id:ID': fake.uuid4(),\n",
    "        'name': fake.name(),\n",
    "        'email': fake.email()\n",
    "    })\n",
    "\n",
    "# Generate Keywords\n",
    "keywords = []\n",
    "for _ in range(NUM_KEYWORDS):\n",
    "    keywords.append({\n",
    "        'Id:ID': fake.uuid4(),\n",
    "        'keyword': fake.word()\n",
    "    })\n",
    "\n",
    "print(\"keywords generated\")\n",
    "\n",
    "# Generate Conferences and Workshops \n",
    "conference_workshop = []\n",
    "for _ in range(NUM_CONFERENCES):\n",
    "    type = random.choice(['Conference', 'Workshop'])\n",
    "    name = f\"{fake.company()} {type}\"\n",
    "    city = fake.city()\n",
    "    month = random.randint(1, 12)\n",
    "    edition = random.randint(1, 100)\n",
    "    \n",
    "    # Create editions held in the same city and month\n",
    "    for year in range(START_YEAR, END_YEAR):\n",
    "        # Get the number of days in the month\n",
    "        num_days = calendar.monthrange(year, month)[1]\n",
    "        day = random.randint(1, num_days)\n",
    "        \n",
    "        # Create the full date\n",
    "        full_date = datetime(year, month, day).strftime('%Y-%m-%d')\n",
    "        \n",
    "        conference_workshop.append({\n",
    "            'Id:ID': fake.uuid4(),\n",
    "            'name': name,\n",
    "            'type': type,\n",
    "            'city': city,\n",
    "            'edition:INT': edition,\n",
    "            'date': full_date,\n",
    "            'year:INT': year,\n",
    "            'month:INT': month,\n",
    "            'day:INT': day\n",
    "        })\n",
    "        edition += 1\n",
    "\n",
    "print(\"conferences and workshops generated\")\n",
    "\n",
    "# Create journals\n",
    "journals = []\n",
    "for _ in range(NUM_JOURNALS):\n",
    "    name= f\"{fake.company()} Journal\"\n",
    "    volume = random.randint(1, 100) # Starting volume\n",
    "\n",
    "    # Create volumes (1-5 per year)\n",
    "    volumes_per_year = random.randint(1, 5)\n",
    "    for year in range(START_YEAR, END_YEAR):\n",
    "        for yearly_volume in range(volumes_per_year):\n",
    "            journals.append({\n",
    "                'Id:ID': fake.uuid4(),\n",
    "                'name': name,\n",
    "                'volume:INT': volume,\n",
    "                'year:INT': year\n",
    "            })\n",
    "            volume += 1\n",
    "\n",
    "print(\"journals generated\")\n",
    "\n",
    "# Generate Papers\n",
    "papers = []\n",
    "written_by = []\n",
    "corresponding_author = []\n",
    "published_in = []\n",
    "journal_author_map = {}\n",
    "conference_author_map = {}\n",
    "for _ in tqdm(range(NUM_PAPERS), desc=\"Generating Papers\", unit=\"paper\"):\n",
    "    paper_id = fake.uuid4()\n",
    "    num_authors = random.randint(1, 5)\n",
    "    authors_for_paper = random.sample(authors, num_authors)\n",
    "    date = fake.date_time_between_dates(START_DATE, END_DATE)\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    paper = {\n",
    "        'Id:ID': paper_id,\n",
    "        'title': fake.sentence(nb_words=6),\n",
    "        'abstract': fake.text(),\n",
    "        'date': date,\n",
    "        'year:INT': year,\n",
    "        'month:INT': month,\n",
    "        'day:INT': day,\n",
    "        'pages:INT': fake.random_int(min=1, max=20),\n",
    "        'doi': fake.uuid4(),\n",
    "        'type': random.choice(['Conference', 'Workshop', 'Journal']),\n",
    "    }\n",
    "    \n",
    "    # Assign authors\n",
    "    for author in authors_for_paper:\n",
    "        written_by.append({\n",
    "            ':START_ID': author['Id:ID'],\n",
    "            ':END_ID': paper_id\n",
    "        })\n",
    "\n",
    "    # Assign corresponding author\n",
    "    corresponding_author.append({\n",
    "        ':START_ID': random.choice(authors_for_paper)['Id:ID'],\n",
    "        ':END_ID': paper_id\n",
    "    })\n",
    "    \n",
    "    # Assign publication \n",
    "    if paper['type'] in ['Conference', 'Workshop']:\n",
    "        candidates = [c for c in conference_workshop if c['type'] == paper['type']]\n",
    "    else:\n",
    "        candidates = journals\n",
    "\n",
    "    # Assign paper to conference/workshop or journal\n",
    "    publication_id = random.choice(candidates)\n",
    "    published_in.append({\n",
    "        ':START_ID': paper_id,\n",
    "        ':END_ID': publication_id['Id:ID']\n",
    "    })\n",
    "\n",
    "    # Create journal/conference author maps to speed up review assignment\n",
    "    if paper['type'] in ['Conference', 'Workshop']:\n",
    "        if publication_id['Id:ID'] not in conference_author_map:\n",
    "            conference_author_map[publication_id['Id:ID']] = set()\n",
    "        conference_author_map[publication_id['Id:ID']].update([a['Id:ID'] for a in authors_for_paper])\n",
    "    else:\n",
    "        if publication_id['Id:ID'] not in journal_author_map:\n",
    "            journal_author_map[publication_id['Id:ID']] = set()\n",
    "        journal_author_map[publication_id['Id:ID']].update([a['Id:ID'] for a in authors_for_paper]) \n",
    "\n",
    "    \n",
    "    papers.append(paper)\n",
    "\n",
    "print(\"papers generated\")\n",
    "\n",
    "# Generate Citations (Paper to Paper relationships)\n",
    "cites = []\n",
    "for paper in papers:\n",
    "    num_citations = random.randint(0, 15)\n",
    "    cited_papers = random.sample(papers, num_citations)\n",
    "    for cited_paper in cited_papers:\n",
    "        # Ensure papers can't cite themselves or papers publised after them\n",
    "        if paper['Id:ID'] != cited_paper['Id:ID'] and paper['date'] > cited_paper['date']:\n",
    "            cites.append({\n",
    "                ':START_ID': paper['Id:ID'],\n",
    "                ':END_ID': cited_paper['Id:ID']\n",
    "            })\n",
    "\n",
    "print(\"citations generated\")\n",
    "\n",
    "# Generate Paper Keywords\n",
    "has_keyword = []\n",
    "for paper in papers:\n",
    "    num_keywords = random.randint(1, 20)\n",
    "    has_keyword.extend([{\n",
    "        ':START_ID': paper['Id:ID'],\n",
    "        ':END_ID': keyword['Id:ID']\n",
    "    } for keyword in random.sample(keywords, num_keywords)])\n",
    "\n",
    "print(\"paper keywords generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Reviewers: 100%|██████████| 5000/5000 [00:05<00:00, 951.68paper/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign Reviewers\n",
    "reviewed_paper = []\n",
    "reviews = []\n",
    "for paper in tqdm(papers, desc=\"Assigning Reviewers\", unit=\"paper\"):\n",
    "    paper_id = paper['Id:ID']\n",
    "    # Get authors for this paper\n",
    "    authors_for_paper = set(relation[':START_ID'] for relation in written_by if relation[':END_ID'] == paper_id)\n",
    "    \n",
    "    # Get the journal or conference this paper is published in\n",
    "    paper_journal = next((pub[':END_ID'] for pub in published_in if pub[':START_ID'] == paper_id and pub[':END_ID'] in journal_author_map), None)\n",
    "    paper_conference = next((pub[':END_ID'] for pub in published_in if pub[':START_ID'] == paper_id and pub[':END_ID'] in conference_author_map), None)\n",
    "    \n",
    "    eligible_reviewers = set()\n",
    "    if paper_journal:\n",
    "        eligible_reviewers = journal_author_map[paper_journal] - authors_for_paper\n",
    "    elif paper_conference:\n",
    "        eligible_reviewers = conference_author_map[paper_conference] - authors_for_paper\n",
    "\n",
    "    if not eligible_reviewers:\n",
    "        print(\"no eligible reviewers\")\n",
    "        continue\n",
    "\n",
    "    # Convert eligible reviewers to a list\n",
    "    eligible_reviewers = list(eligible_reviewers)\n",
    "\n",
    "    # Assign 3 reviewers to each paper\n",
    "    reviewers = random.sample(eligible_reviewers, min(3, len(eligible_reviewers)))\n",
    "    for reviewer_id in reviewers:\n",
    "        \n",
    "        # Assign reviewer to paper\n",
    "        reviewed_paper.append({\n",
    "            ':START_ID': reviewer_id,\n",
    "            ':END_ID': paper_id\n",
    "        })\n",
    "\n",
    "print(\"reviews generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files generated.\n"
     ]
    }
   ],
   "source": [
    "def output_to_csv(data, filename):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = data[0].keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for item in data:\n",
    "            writer.writerow(item)\n",
    "\n",
    "# Output nodes and relationships to CSV\n",
    "output_to_csv(authors, 'data/authors.csv')\n",
    "output_to_csv(keywords, 'data/keywords.csv')\n",
    "output_to_csv(conference_workshop, 'data/conference_workshop.csv')\n",
    "output_to_csv(journals, 'data/journals.csv')\n",
    "output_to_csv(papers, 'data/papers.csv')\n",
    "output_to_csv(written_by, 'data/r_written_by.csv')\n",
    "output_to_csv(corresponding_author, 'data/r_corresponding_author.csv')\n",
    "output_to_csv(published_in, 'data/r_published_in.csv')\n",
    "output_to_csv(cites, 'data/r_cites.csv')\n",
    "output_to_csv(has_keyword, 'data/r_has_keyword.csv')\n",
    "output_to_csv(reviewed_paper, 'data/r_reviewed_paper.csv')\n",
    "\n",
    "print(\"CSV files generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
